{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMiuNqYuWDz4RDws1d3noSx",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/EvgeniaKantor/MeNow/blob/main/Toxicity.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd"
      ],
      "metadata": {
        "id": "raCnGzvm76U8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ME4l7gvj7l5e"
      },
      "outputs": [],
      "source": [
        "df = pd.read_excel('df_with_toxicity_info.xlsx')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Adding an empty column 'Toxic or Nontoxic'\n",
        "df['Toxic_Gemini'] = None"
      ],
      "metadata": {
        "id": "R2Mx5uNP7qkz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import google.generativeai as genai\n",
        "import os\n",
        "import time\n",
        "import re\n",
        "from google.api_core.exceptions import ServiceUnavailable\n",
        "from google.colab import userdata\n",
        "\n",
        "# Retrieve and set the API key\n",
        "GOOGLE_API_KEY = userdata.get('gemini_key')\n",
        "os.environ['GOOGLE_API_KEY'] = GOOGLE_API_KEY\n",
        "\n",
        "# Configure the generative AI client\n",
        "genai.configure(api_key=GOOGLE_API_KEY)\n",
        "\n",
        "# Load the generative model\n",
        "model = genai.GenerativeModel('gemini-pro')\n",
        "\n",
        "# Function to clean text in the abstract\n",
        "def clean_text(text):\n",
        "    text = text.lower()  # Convert to lowercase\n",
        "    text = re.sub(r'\\s+', ' ', text)  # Remove extra spaces\n",
        "    text = re.sub(r'[^a-zA-Z0-9\\s]', '', text)  # Remove special characters\n",
        "    return text.strip()  # Strip leading and trailing spaces\n",
        "\n",
        "# Function to generate toxicity information from abstract\n",
        "def get_toxicity(abstract):\n",
        "    query = (\n",
        "        f\"Determine if Withania Somnifera is toxic to humans based on the following abstract (\"\n",
        "        f\"Respond with 'Toxic' or 'Nontoxic').\\n\\nAbstract:\\n{abstract}\"\n",
        "    )\n",
        "    retries = 3  # Number of retries\n",
        "    delay = 5  # Initial delay in seconds\n",
        "\n",
        "    while retries > 0:\n",
        "        try:\n",
        "            response = model.generate_content(query)\n",
        "            if response and response.candidates and response.candidates[0].content.parts:\n",
        "                response_content = response.candidates[0].content.parts[0].text.strip()\n",
        "                return response_content\n",
        "            else:\n",
        "                print(f\"No valid content found for abstract: {abstract}\")\n",
        "                return None\n",
        "        except IndexError as e:\n",
        "            print(f\"IndexError: {str(e)}\")\n",
        "            return None\n",
        "        except ServiceUnavailable as e:\n",
        "            print(f\"Service unavailable. Retrying in {delay} seconds...\")\n",
        "            time.sleep(delay)\n",
        "            retries -= 1\n",
        "            delay *= 2  # Exponential backoff\n",
        "        except Exception as e:\n",
        "            print(f\"Exception: {str(e)}\")\n",
        "            return None\n",
        "    else:\n",
        "        print(f\"Maximum retries reached for abstract: {abstract}. Unable to generate toxicity.\")\n",
        "        return None\n",
        "\n",
        "# Add a new column for cleaned abstracts\n",
        "df['Cleaned_Abstract'] = df['Abstract'].apply(lambda x: clean_text(x) if pd.notna(x) else '')\n",
        "\n",
        "# Rate limiting parameters\n",
        "delay_between_requests = 1  # Delay in seconds between requests\n",
        "\n",
        "# Generate toxicity information for each cleaned abstract\n",
        "for index, row in df.iterrows():\n",
        "    try:\n",
        "        if pd.isna(row['Toxic or Nontoxic']) or row['Toxic or Nontoxic'] == '':  # Check if cell is empty\n",
        "            print(f\"Processing index {index}...\")\n",
        "            toxicity_info = get_toxicity(row.get('Cleaned_Abstract', ''))\n",
        "            if toxicity_info:\n",
        "                df.at[index, 'Toxic or Nontoxic'] = toxicity_info\n",
        "                print(f\"Generated toxicity information for index {index}: {toxicity_info}\")\n",
        "            time.sleep(delay_between_requests)  # Delay between requests\n",
        "    except Exception as e:\n",
        "        print(f\"Failed to generate toxicity information for index {index}: {e}\")"
      ],
      "metadata": {
        "id": "gF6eHcp27tsm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#save df\n",
        "df.to_excel('df.xlsx', index=False)"
      ],
      "metadata": {
        "id": "mC-Oo_mf72EJ"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}